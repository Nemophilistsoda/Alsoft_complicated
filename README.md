### 第二部分：样本数据预处理（30分） 

##### 【2021网络赛】 
 任务：按照要求对给定 csv 格式数据进行处理。
task2.csv
task2.csv
文件为本题的数据文件。利用 Python 编写代码完成以下任务：
1. 分别求取 `Max TemperatureF` 和 `Min TemperatureF` 两个特征的均值和方差。
2. 对 `Mean TemperatureF` 特征进行标准化，输出标准化之后的 `Mean TemperatureF` 特征的均值。

标准化采用计算公式如下：
$$x' = \frac{x - \min(x)}{\max(x) - \min(x)}$$
其中，$x$ 表示标准化之前的特征，$x'$ 表示标准化之后的特征。

 说明：将代码源文件与运行结果截图放入答题卡对应位置。
解答：

##### 【2022校赛】 
- 任务：按照要求对给定csv格式数据进行处理。 
  - `task2.csv` 文件为本题的数据文件。利用Python编写代码完成以下任务： 
    1. 分别求取 `sensor_1`，`sensor_2` 两个特征的均值和方差。 
    2. 对 `sensor_1`，`sensor_2` 特征进行Z - score标准化，输出标准化之后的 `sensor_1`，`sensor_2` 的均值和方差。 
    - 标准化采用计算公式如下： 
      $x'=\frac{x - \mu}{\sigma}$
      其中，$x$ 表示标准化之前的特征，$x'$ 表示标准化之后的特征。 
  - 说明：将代码源文件与运行结果截图放入答题卡对应位置。 

##### 【2022网络赛】 
注：任务1 与任务2 都需要完成。 
- 任务1：按照要求对给定文本数据进行处理（15分）。 
  - “第二部分/任务2/task2_1.txt” 文件为本题的数据文件，即语料库；其中含有6行文本，每一行即是一篇文档，现要求利用Python编写代码完成以下任务： 
    1. 计算每一行单词的TF - IDF 值，按照TF - IDF 值的大小以降序形式输出（大小写不敏感，即统一转为小写字母处理）。 
    - 输出示例：语句1：[('this':0.8), ('is':0.7),………] 
      语句2：[('this':0.8), ('is':0.7),………] 
  - 说明： 
    1. 将代码源文件与运行结果截图放入比赛环境中本题对应的提交目录文件夹 （user/Q2/1 文件夹）。 
    2. 可以使用sklearn 库或直接根据公式进行计算。 
    3. 某一个词 $x$ 的 $TF - IDF$ 值计算公式如下： 
      $TF - IDF(x) = TF(x)*IDF(x)$ 
      其中： 
        $TF(x)=\frac{x在文章中出现的次数}{文章的总词数}$ 
        $IDF(x)=\log(\frac{语料库的文档总数}{包含词x的文档数 + 1})$ 
- 任务2：按照要求对给定图片数据进行处理（15分）。 
  - “第二部分/任务2” 文件夹为本题的数据文件，其中含有4张不同尺寸的图片，现要求： 
    1. 首先将所有图片长宽统一缩放至 800*800，然后将图片均分为四等份并截取右下部分子区域作为新图像，并将新图像以原始文件名进行保存，保存文件夹目录为 “user/Q2/2”；
    2. 对上一步获得的每一张新图像进行Harris 角点检测，检测出的角点在图像上画，将四张处理之后的图片以两行两列的形式在一个窗口进行显示。 
  - 说明：将代码源文件及运行结果截图放入比赛环境中本题对应的提交目录文件夹（user/Q2/2 文件夹）。 
  注：图片路径中含有中文，请谨慎处理。 

##### 【2022省决赛】 
注：任务1、任务2 和任务3 都需要完成。 

- 任务1：按照要求对给定文本数据进行处理（15 分）。 
  - “任务1/task2_1.txt” 文件为本题的数据文件，即语料库；其中含有4 行中文文本，每一行即是一篇文档（词的间隔已用空格分开，无需分词），现要求利用Python 编写代码完成以下任务： 
    1. 计算每一行文本的TF - IDF 值，按照TF - IDF 值的大小以降序形式输出。 
    - 输出示例：语句1：[('我':0.8), ('北京':0.7),………] 
      语句2：[('小明':0.8), ('毕业':0.7),………] 
  - 说明： 
    1. 将代码源文件与运行结果截图放入答题卡对应位置的同时保存在文件夹 user/Q2/1 中一份。 
    2. 可以使用sklearn 库或直接根据公式进行计算。 
    3. 某一个词 $x$ 的 $TF - IDF$ 值计算公式如下： 
      $TF - IDF(x) = TF(x)*IDF(x)$ 
      其中： 
        $TF(x)=\frac{x在文章中出现的次数}{文章的总词数}$ 
        $IDF(x)=\log(\frac{语料库的文档总数}{包含词x的文档数 + 1})$ 
- 任务2：按照要求对给定图片数据进行处理（10 分）。 
  - “第二部分/任务2/” 文件夹为本题的数据文件夹，含有两张同样尺寸的图片（1.jpg和2.jpg），现要求使用Python 结合OpenCV 库编写代码实现以下功能： 
    1. 提取每一张图片的ORB 特征并显示；  
    2. 根据（1）提取的特征拼接两幅图像，并显示拼接之后的结果。 
  - 说明：将代码源文件、处理结果及运行结果截图放入答题卡对应位置的同时保存在文件夹user/Q2/2 中一份。 
- 任务3：按照要求利用模板匹配算法实现目标定位功能（5 分）。 
  - “第二部分/任务3/” 文件夹中的 “template.png” 为模板图像，“image.png” 为目标图像，现要求使用Python 编写代码实现以下功能： 
    1. 利用模板匹配算法在目标图像中找到与模板图像最匹配的矩形位置坐标； 
    2. 将定位结果以绿色矩形框显示在目标图像上。 
  - 说明：将代码源文件及运行结果截图放入比赛环境中本题对应的提交目录文件夹（user/Q2/3 文件夹）。 

##### 【2023校赛】 
- 任务：按照要求对给定文本数据进行处理 (10 分) 。 
  - “任务 1/task2_1.txt” 文件为本题的数据文件；其中含有 4 行英文文本（假定各词之间已经用空格分词，无需再进行分词），现要求利用Python编写代码 完成以下任务： 
    1. 输出的各行文本每个词的 TF - IDF 值 
    2. 计算每行样本之间的余弦相似度（cosine_similarity）。 
      $\cos(x,y)=\frac{x\cdot y}{||x||\cdot||y||}$
  - 说明：将代码源文件、处理结果及运行结果截图放入答题卡对应位置的同时保存在文件夹 user/Q2/1 中一份 
- 任务：按照要求对给定图片数据进行处理 (10分) 。 
  - “第二部分/任务 2/” 文件夹为本题的数据文件夹，含有PCB_images.ZIP文件，对文件解压缩后，使用 Python 结合 OpenCV 库或者其他库编写代码实现以下功能： 
    1. 遍历PCB_images 文件夹下的各子文件夹中的所有图片，对图片做水平翻转，并将水平翻转后的图片重新命名，规则如下：原来文件名前面加上“flip_”，如：01_missing_hole_01.jpg 变为 flip_01_missing_hole_01.jpg。 
    2. 新文件保存在新的文件夹“flip_PCB_images”中，flip_PCB_images 文件夹下的各子文件夹按照原来文件夹名命名。 
  - 说明：将代码源文件、处理结果及运行结果截图放入答题卡对应位置的同时保存在文件夹 user/Q2/2 中一份。 
- 任务：按照要求实现图片旋转及保存功能 (10分)。 
  - “第二部分/任务 3/” 文件夹中的 “image.png” 为目标图像，现要求使用Python 编写代码实现以下功能： 
    1. 写一个函数通过改变函数参数“angle”分别实现对“image.png”不同角度的旋转； 
    2. 调用该函数，将该图片旋转15°、45°、60°，将图片重新命名保存到原文件夹中。 
  - 说明：将代码源文件及运行结果截图放入比赛环境中本题对应的提交目录文件夹(user/Q2/3 文件夹) 。 

##### 【2023网络赛】 
- 任务1：按照要求对给定数据进行处理（15分）。 
  - “data/task2/task2_1.csv” 文件为本题的数据文件，现要求利用Python编写代码完成以下任务： 
    1. 根据 `WORK_PROVINCE` 列统计非字母组合代码的样本个数。 
    2. 计算 `AVG_FLIGHT_COUNT` 列最大的20个数值的平均值。 
  - 说明： 
    1. 将代码源文件与运行结果截图放入答题卡对应位置。 
- 任务2：按照要求使用Python编程对给定图片数据进行处理（15分）。 
  - “data/task2/task2_2.jpg” 为本题的数据文件，现要求： 
    1. 将图片 `task2_2.jpg` 长宽缩放至650*360（宽*高），然后将图片按列均分为2等份并截取右部分子区域作为新图像（命名为 `img1`）； 
    2. 将上一步获得的新图像 `img1` 转换到YCrCb颜色空间（命名为 `img2`）； 
    3. 创建一个和 `img2` 同样尺寸的全黑图像（命名为 `img3`）；对 `img2` 进行遍历操作，记录其Cr分量在133至173之间、Cb分量在77至127之间的像素位置，将 `img3` 对应像素位置的像素值置为白色。 
    4. 同时显示 `img1` 和处理之后的 `img3`。 
  - 说明：将代码源文件及运行结果截图放入题卡对应位置。 

##### 【2023省决赛】 
- 任务1：按照要求对给定数据进行处理（15分）。 
  - “data/task2/task2_1.csv” 文件为本题的数据文件，其中前三列为特征，最后一列为标签，现要求利用Python编写代码完成以下任务： 
    1. 将缺失值用均值填充，并将填充之后对应行完整数据输出； 
    2. 将非数值数据转换为数值数据（转换之后的数据为0,1,2,3,…这种标签数值数据），输出转换之后的矩阵完整数据。 
  - 说明： 
    1. 将代码截图文件与运行结果截图放入答题区域。 
- 任务2：按照要求使用Python编程对给定图片数据进行处理（15分）。 
  - “data/task2/task2_2.png” 为本题的数据文件，有一种低光照图像增强算法的步骤如下，请按下述步骤编程实现： 
    1. 将原始图像进行BGR三通道分离； 
    2. 根据G通道图像进行反色计算增强系数alpha，即 `alpha = 255 - G`; 
    3. 将alpha作为系数调整原始BGR三通道像素值，调整公式为: 
      `B_1 = B * alpha / 255` 
      `G_1 = G * alpha / 255` 
      `R_1 = R * alpha / 255` 
    4. 根据以下公式融合原始B、G、R和调整之后的B_1、G_1、R_1 
      `B_new = 255 - ((255 - (B))*(255 - (B_1)) / 255)` 
      `G_new = 255 - ((255 - (G))*(255 - (G_1)) / 255)` 
      `R_new = 255 - ((255 - (R))*(255 - (R_1)) / 255)` 
    5. 融合B_new、G_new、R_new获得低光照增强之后的图像； 
    6. 同时显示原始图像和低光照增强之后的图像。 
  - 说明：将代码截图及运行结果截图放入答题区域。（在编程实现时请注意图像数据的格式及有效范围）。

### 第三部分：传统机器学习算法设计及应用（20分）
##### 【2021网络赛】 
任务：根据要求补全对应算法代码。 
task3.txt
    task3.txt
为本题的数据文件，其内容为我国部分城市的经纬度坐标。
task3.py 为本题的代码文件。要求完成以下两个任务： 
    （1）根据经纬度坐标将所有数据利用Kmeans算法聚为10类； 
（2）将聚类结果进行可视化（每一个城市表示为2维坐标平面的一个点，每一类中的
点用同一种颜色，不同类的点采用不同颜色）。 
说明：将所补充代码源文件与运行结果截图放入答题卡对应位置。 
附task3.py 
```python
import numpy as np 
import matplotlib.pyplot as plt 
from sklearn.cluster import KMeans 

# 读取原始数据 
X = [] 
f = open('task3.txt') 
lineIndex = 1 
for v in f: 
    if lineIndex > 1: 
        X.append([float(v.split()[1]), float(v.split()[2])]) 
    lineIndex += 1 
f.close()  # 关闭文件

# 转化为numpy array 
X = np.array(X) 

# 类簇的数量 
n_clusters = 10 

# 需要选手补全部分
kmeans = KMeans(n_clusters=n_clusters)
kmeans.fit(X)
labels = kmeans.labels_
centroids = kmeans.cluster_centers_

# 可视化聚类结果
colors = ['r', 'g', 'b', 'c', 'm', 'y', 'k', 'orange', 'purple', 'brown']
for i in range(n_clusters):
    cluster_points = X[labels == i]
    plt.scatter(cluster_points[:, 0], cluster_points[:, 1], c=colors[i], label=f'Cluster {i+1}')

plt.scatter(centroids[:, 0], centroids[:, 1], marker='x', s=200, linewidths=3, color='w', zorder=10)
plt.title('China')
plt.legend()
plt.show()
```

##### 【2022校赛】 
- 任务：根据要求补全对应算法代码。 
  - `task3.txt` 为本题的数据文件，其内容为鸢尾花Iris数据（`Iris.txt`）。数据的前3列
  为数据属性，最后一列为鸢尾花的类别。要求完成以下两个任务： 
    1. 对数据进行可视化（每一种鸢尾花用同一种颜色，不同类的点采用不同颜色）。 
    2. 根据数据的前3列数据，将数据利用Kmeans算法聚为3类； 
    3. 将聚类结果进行可视化（聚类为同一种类别的用同一种颜色，不同聚类结果采用
  不同颜色。）。 
- 说明：将源文件与运行结果截图放入答题卡对应位置。 

##### 【2022网络赛】 
- 任务：使用Python 编写代码解决对应问题。 
  - “第三部分/task3data.csv”为本题的数据文件，共569 行、31 列。每一行代表一条
  样本数据，前30 列为特征，第31 列为类别标签（二分类任务）。现要求利用Python 编写
  代码实现如下功能： 
    1. 准确加载数据集； 
    2. 使用最大值最小值归一化方法将30维特征进行归一化（0 - 1）； 
    3. 对数据集切分，将前500行作为训练集，后69行作为测试集； 
    4. 使用sklearn库中SVM 模型在训练集上进行训练； 
    5. 使用（4）训练得到的模型在测试集上进行测试，输出测试集分类准确率。 
- 说明： 
  - 最大值最小值归一化公式为：$x_{i,j}^* = \frac{x_{i,j} - \min(x_j)}{\max(x_j) - \min(x_j)}$

##### 【2022省决赛】 
- 任务:使用 Python 编写代码解决对应问题。
  - “第三部分/task3data.csv”为本题的数据文件，共 569 行、31 列。每一行代表一条样本数据，前 30 列为特征，第 31 列为类别标签(二分类任务)。现要求利用 Python 编写代码实现如下功能:
    1. 准确加载数据集;
    2. 使用 z - score 标准化方法将 30 维特征进行标准化(均值为 0，方差为 1);
    3. 对数据集切分，将前 500 行作为训练集，后 69 行作为测试集;
    4. 使用 sklearn 库中决策树模型(分类树)在训练集上进行训练;
    5. 使用(4)训练得到的模型在测试集上进行测试，输出测试集分类准确率。
- 说明:
  - 决策树最大深度设置为 10;
  - 数据预处理部分可以使用第三方库;
  - 只考察解决问题的完整流程，不对最终准确率进行排名比较;
  - 将代码源文件与运行结果截图放入比赛环境中本题对应的提交目录文件夹 (user/Q3 文件夹)。

##### 【2023校赛】 
- 任务：使用 Python 编写代码解决对应问题。 
  - “第三部分/train.csv”，“test.csv”为本题的数据文件，其中 `train.csv` 包括 891 行，12 列的数据，`test.csv` 包括 418 行，11 列的数据，每一行代表一条样本数据。数据相关列的含义如下： 
  - 现要求利用 Python 编写代码实现如下功能：（代码中请加上每个任务的注释） 
    1. 准确加载数据集； 
    2. 检查数据是否有缺失，如有缺失按照以下规则对缺失值进行填充； 
      - 若特征为定量的数值类型按照中位数进行填充；若为定性的分类变量数据按照本列最大频率的值填充。 
    3. 丢弃 `Cabin`（船仓编号）、`Ticket`（船票编号）、`Name`（乘客姓名）、`PassengerId`（乘客编号）等特征。 
    4. 特征值处理，对 `Pclass`, `Sex`, `Embarked` 进行独热编码； 
    5. 对训练集切分； 
    6. 采用随机森林分类器在训练集上进行训练； 
    7. 通过绘制混淆矩阵输出模型在训练集上的错分情况； 
    8. 用训练得到的模型在测试集上进行测试，并生成预测文件 `result.csv`。其中第一列为 `PassengerId` ，第二列为 `Survived`。 
- 说明： 
  - 数据预处理部分可以使用第三方库； 
  - 只考察解决问题的完整流程，不对最终准确率进行排名比较； 
  - 将代码源文件与运行结果截图放入比赛环境中本题对应的提交目录文件夹 (user/Q3 文件夹) 。 

##### 【2023网络赛】 
- 任务：“data/task3”为本题的数据文件，具有两个子文件夹（分别含有猫和狗）和一个单独图像文件。现要求利用 Python 编写代码利用 OpenCV 与 scikit - learn 库实现基于词袋 (Bag of Word) 模型的图像分类，具体要求如下： 
  1. 图像的特征表示使用 OpenCV 的 SIFT 特征点提取算法； 
  2. 特征描述子的聚类使用 scikit - learn 中的 Kmeans 聚类算法； 
  3. 通过 scikit - learn 的线性 SVM 模型训练实现分类模型训练（训练测试数据集比例为 9:1）； 
  4. 输出测试集的 precision, recall, 和 F1 - score。 
- 说明： 
  - 未明确要求的模型参数可以自行设定 
  - 将代码源文件与运行结果截图放入题卡对应位置。 

##### 【2023省决赛】 
- 任务：“data/task3”为本题的数据文件，具有一个图片文件夹 `data` 和一张图片 `image_0002.jpg`。现要求利用 Python 编写代码利用 OpenCV 实现基于 SIFT 特征点的图像检索功能，具体要求如下： 
  1. 图像的特征表示使用 OpenCV 的 SIFT 特征点提取算法； 
  2. `image_0002.jpg` 为查询图像，要求从 `data` 文件夹中利用 SIFT 匹配返回距离最相近的三张图像； 
  3. 每幅图像的描述子个数固定设置为 32，图片的特征距离采用余弦距离； 
  4. 显示和查询图像距离最近的三张图像。 
- 说明： 
  - 未明确要求的模型参数可以自行设定 
  - 将代码截图与运行结果截图放入答题区域。


### 第四部分：深度学习算法设计及应用（15分）
##### 【2021网络赛】 
- **任务**：图片回归模型训练。
  - 给定数据：`imgdata.rar` 为一批人脸图片及每一张人脸对应的年龄标签 `label.txt` 数据。
  - 要求把所有已给的数据当作训练集训练一个基于卷积神经网络的人脸年龄预测模型。
- **要求与说明**：
  1. 本题旨在考察参赛者使用深度学习库解决具体计算机视觉问题的完整流程，不以测试集准确率作为评分标准。
  2. 输入网络的数据尺寸统一缩放到 64*64*3。
  3. 使用 Adam 优化器。
  4. 使用均方误差损失函数（MSE）。
  5. 代码能正常运行，输出每一次迭代的损失值情况。
  6. 使用深度学习库 PyTorch 或 Tensorflow 均可。
  7. **卷积神经网络的结构**：
| 层名称 | 参数配置 |
| --- | --- |
| 输入层 | 64*64*3 |
| 非线性映射层 1 | - |
| 卷积层 1 | 共 8 个 3*3 的卷积核，步长为 1，无 padding；非线性映射函数为 Relu |
| 池化层 1 | 最大值池化，核 2*2，步长为 2 |
| 卷积层 2 | 共 16 个 3*3 的卷积核，步长为 1，无 padding |
| 非线性映射层 2 | - |
| 池化层 2 | 最大值池化，核 2*2，步长为 2；非线性映射函数为 Relu |
| 卷积层 3 | 共 32 个 3*3 的卷积核，步长为 1，无 padding |
| 非线性映射层 3 | 非线性映射函数为 Relu |
| 池化层 3 | 最大值池化，核 2*2，步长为 2 |
| 全连接层 1 | 128 个神经元 + Relu 非线性映射 |
| Dropout | 激活概率为 0.5 |
| 全连接层 2 | 1 个神经元 + Relu 非线性映射 |
  8. 需提交所有代码及成功训练运行截图。

##### 【2022校赛】 
- **任务**：图片分类模型构建与训练。
  - 给定病人的眼底图片，根据图片构建深度学习模型判断其是病理性近视还是非病理性近视。
  - 数据集中既有病理性近视患者的眼底图片，也有非病理性近视患者的图片。命名规则如下：
    - 病理性近视（PM）：文件名以 P 开头。
    - 非病理性近视（non - PM）包括高度近视（high myopia）：文件名以 H 开头，正常眼睛（normal）：文件名以 N 开头。
    - 病理性患者的图片要求作为正样本，标签为 1；非病理性患者的图片要求作为负样本，标签为 0。
- **要求与说明**：
  1. 本题旨在考察参赛者使用深度学习库解决具体计算机视觉问题的完整流程，不以测试集准确率作为评分标准。
  2. 输入网络的数据尺寸统一缩放到 224*224*3。
  3. 使用 Adam 优化器。
  4. 使用交叉熵损失。
  5. 代码能正常运行，输出二次迭代的损失值情况。
  6. 使用深度学习库 PyTorch、Tensorflow、paddlepaddle 均可。
  7. **卷积神经网络的结构**：
| 层名称 | 参数配置 |
| --- | --- |
| 输入层 | 224*224*3 |
| 卷积层 1 | 共 6 个 5*5 的卷积核，步长为 1，无 padding |
| 非线性映射层 1 | 非线性映射函数为 Relu |
| 池化层 1 | 最大值池化，核 2*2，步长为 2 |
| 卷积层 2 | 共 16 个 5*5 的卷积核，步长为 1，无 padding |
| 非线性映射层 2 | - |
| 池化层 2 | 最大值池化，核 2*2，步长为 2；非线性映射函数为 Relu |
| 卷积层 3 | 共 120 个 4*4 的卷积核，步长为 1，无 padding |
| 非线性映射层 3 | 非线性映射函数为 Relu |
| 全连接层 1 | 64 个神经元 + Relu 非线性映射 |
| Dropout | 激活概率为 0.5 |
| 全连接层 2 | 2 个神经元 + Relu 非线性映射 |
  8. 需提交所有代码及成功训练运行截图。

##### 【2022网络赛】 
- **任务**：图片多标签分类模型训练。
  - “第四部分”文件夹为本题的数据文件，含有 100 张交通场景监控图片及其对应的训练和测试标签文件 `trainlabels.txt` 和 `testlabels.txt`。标签文件第 1 列表示图片路径，第 2 - 8 列表示其对应的图片中是否存在对应的车型，若存在则用 1 表示，若不存在则用 0 表示。
  - 请根据要求利用卷积神经网络实现图片的多标签分类功能。
- **要求与说明**：
  1. 本题旨在考察参赛者使用深度学习库解决具体计算机视觉问题的完整流程，不以测试集准确率作为评分标准。
  2. 输入网络的图片数据尺寸统一缩放到 64*64*3。
  3. 网络的输出层为全连接神经网络，其中的每一个神经元对应一个物体类别，中间层自由搭建，但要保证维度匹配、代码可运行。
  4. 使用 Adam 优化器。
  5. 使用 L1 损失函数。
  6. 代码能正常运行，输出每一次或每一轮迭代的损失值情况。
  7. 使用深度学习库 PyTorch 或 Tensorflow 均可。
  8. 在训练集进行训练，在测试集进行测试。
  9. 需将所有代码及成功训练运行截图放入比赛环境中本题对应的提交目录文件夹（user/Q4 文件夹）。

##### 【2022省决赛】 
- **任务**：人脸图片关键点回归模型训练。
  - “第四部分”文件夹为本题的数据文件，含有 150 张人脸图片及其对应的训练和测试标签文件 `train.txt` 和 `test.txt`。标签文件第 1 列表示图片文件名，第 2 - 11 列表示其对应的人脸图片的五个关键点的坐标（x1,y1,x2,y2,…x5,y5）。
  - 请根据要求利用卷积神经网络实现人脸图片的关键点定位功能。
- **要求与说明**：
  1. 本题旨在考察参赛者使用深度学习库解决具体计算机视觉问题的完整流程，不以测试集准确率作为评分标准。
  2. 输入网络的图片数据尺寸统一缩放到 64*64*3。
  3. 网络的输出层为全连接神经网络，共 10 个神经元，分别对应五个关键点的坐标，中间层自由搭建，但要保证维度匹配、代码可运行。
  4. 使用 Adam 优化器。
  5. 使用 L1 损失函数。
  6. 代码能正常运行，输出每一次或每一轮迭代的损失值情况。
  7. 使用深度学习库 PyTorch 或 Tensorflow 均可。
  8. 在训练集进行训练，在测试集进行测试。
  9. 需将所有代码及成功训练运行截图放入比赛环境中本题对应的提交目录文件夹（user/Q4 文件夹）。

##### 【2023校赛（第一个）】 
- **任务**：使用 Python 编写代码解决对应问题。
  - “第三部分/train.csv”，“test.csv”为本题的数据文件，其中 `train.csv` 包括 891 行，12 列的数据，`test.csv` 包括 418 行，11 列的数据，每一行代表一条样本数据。
  - 现要求利用 Python 编写代码实现如下功能：
    1. 准确加载数据集。
    2. 检查数据是否有缺失，如有缺失按照以下规则对缺失值进行填充：若特征为定量的数值类型按照中位数进行填充；若为定性的分类变量数据按照本列最大频率的值填充。
    3. 丢弃 `Cabin`（船仓编号）、`Ticket`（船票编号）、`Name`（乘客姓名）、`PassengerId`（乘客编号）等特征。
    4. 特征值处理，对 `Pclass`, `Sex`, `Embarked` 进行独热编码。
    5. 对训练集切分。
    6. 采用随机森林分类器在训练集上进行训练。
    7. 通过绘制混淆矩阵输出模型在训练集上的错分情况。
    8. 用训练得到的模型在测试集上进行测试，并生成预测文件 `result.csv`。其中第一列为 `PassengerId` ，第二列为 `Survived`。
- **说明**：
  1. 数据预处理部分可以使用第三方库。
  2. 只考察解决问题的完整流程，不对最终准确率进行排名比较。
  3. 将代码源文件与运行结果截图放入比赛环境中本题对应的提交目录文件夹 (user/Q3 文件夹)。

##### 【2023校赛（第二个）】 
- **任务**：人脸旋转角度预测模型构建。
  - 赛题背景：自动识别人脸的旋转角度在实际应用中可以用作人脸的姿态矫正，以及手机智能切换显示方向等等。
  - “第四部分”文件夹为本题的数据文件，仅含有 150 张人脸图片。请利用该数据集构建一个 CNN 深度网络，该网络可以完成人脸旋转角度值的预测任务。
  - 提示：可以对 150 张图片进行随机旋转操作来构造训练集和测试集，旋转后的图片和旋转角度可作为一组数据。为简化问题这里的旋转角度控制在[-60,60]之间。
  - 对二维图片中的人脸旋转 (Roll) 角度进行预测。
- **要求与说明**：
  1. 本题旨在考察参赛者使用深度学习库解决具体计算机视觉问题的完整流程，不以测试集准确率作为评分标准。
  2. 先完成人脸旋转角度检测任务的数据集构建。
  3. 代码能正常运行，输出每一次或每一轮迭代的损失值情况。
  4. 使用深度学习库 PyTorch 或 Tensorflow 均可。
  5. 在训练集进行训练，在测试集进行测试。
  6. 需将所有代码及成功训练运行截图放入比赛环境中本题对应的提交目录文件夹 (user/Q4 文件夹) 。

##### 【2023网络赛】 
- **任务**：图片多标签分类模型训练。
  - “data/task4”文件夹为本题的数据文件，含有 100 张交通场景监控图片及其对应的训练和测试标签文件 `trainlabels.txt` 和 `testlabels.txt`。标签文件第 1 列表示图片路径，第 2 - 8 列表示其对应的图片中是否存在对应的车型，若存在则用 1 表示，若不存在则用 0 表示。
  - 请根据要求利用卷积神经网络实现图片的多标签分类功能。
- **要求与说明**：
  1. 本题旨在考察参赛者使用深度学习库解决具体计算机视觉问题的完整流程，不以测试集准确率作为评分标准。
  2. 输入网络的图片数据尺寸统一缩放到 64*64*3。
  3. 网络的输出层为具有 Sigmoid 激活的全连接神经网络，其中的每一个神经元对应一个物体类别，中间层自由搭建，但要保证维度匹配、代码可运行。
  4. 使用 SGD 优化器，初始学习率 0.001，weight decay 为 0.0001。
  5. 使用 L2 损失函数。
  6. 代码能正常运行，输出每一次或每一轮迭代的损失值情况。
  7. 使用深度学习库 PyTorch 或 Tensorflow 均可。
  8. 在训练集进行训练，在测试集进行测试。
  9. 需将所有代码及成功训练运行截图放入题卡对应位置。

### 【2023省决赛】 
- **任务**：时序数据预测。
  - “data/task4/task4.csv”为本题的数据文件，每一行数据表示月份及其对应的用电量。
  - 请根据要求利用 LSTM 网络实现时序数据预测功能。
- **要求与说明**：
  1. 本题旨在考察参赛者使用深度学习库解决具体问题的完整流程，不以准确率作为评分标准。
  2. 在数据训练前需要进行归一化处理，将所有数据映射到 0 - 1 之间。
  3. 网络的能力为根据任意过去 6 个月的用电数据预测未来一个月的用电数据（其中 90% 作为训练集，10% 作为验证集），中间层自由搭建，但要保证维度匹配、代码可运行（由于比赛平台的算力限制，建议 LSTM 和全连接只设置 1 层，隐含层和全连接层的特征维度都设置为 10；否则模型过大可能会导致平台卡死，需要重新初始化进入）。
  4. 使用 Adam 优化器，初始学习率 0.0002。
  5. 使用 MSE 损失函数。
  6. 代码能正常运行，输出在训练集和验证集的每一次或每一轮迭代的损失值情况，总共训练 2 个 epoch（平台算力限制，过多的训练轮数可能会导致平台卡死，需要重新初始化进入）。
  7. 使用深度学习库 PyTorch 或 Tensorflow 均可。
  8. 需将所有代码截图及成功训练运行截图放入答题区域。

### 第五部分：人工智能技术综合应用（20分）
【2021网络赛】 
任务：根据房源信息，预测房屋价格。（数据为 train.CSV
 val.CSV
 test.CSV
 , test.CSV
 train.CSV
 , 
val.CSV
） 
  房源信息包括：电梯情况|楼层|户型|区域|装修情况|面积|建筑时间|。 
  注：部分信息有缺失。训练集：验证集：测试集=17000：3000：3000 
要求与说明： 
（1）根据训练集数据训练一个房屋出租价格预测模型。 
（2）按解决问题的顺序详细介绍每一步的目的，并给出相应代码，放入答题卡对应位置。 
（3）计算在验证集表现最好的模型在测试集数据的预测结果，将输出结果放入答题卡对应
位置（输出结果保存为txt格式并命名为task5result.txt，不能截图）。 
输出txt格式的数据每一行是测试集对应房源的预测价格（一定要符合格式要求，否
则自动评分程序无法正确执行） 
例： 
800 
120 
615 
… 
（共3000行） 
注：最终需要在规定位置提交的文件包括答题卡和task5result.txt。  
23 
【2022校赛】 
任务：根据房源信息，预测房屋价格。（数据为boston_train.CSV, boston_test.CSV） 
数据集为波士顿房价数据集。该地区的房价受诸多因素影响。该数据集统计了13种可能影 
响房价的因素和该类型房屋的均价，期望构建一个基于13个因素进行房价预测的模型。各 
属性名和含义如下： 
（MEDV 列即需要预测的价格） 
要求与说明： 
（1）根据训练集数据训练一个房屋出租价格预测模型。 
（2）按解决问题的顺序详细介绍每一步的目的，并给出相应代码，放入答题卡对应位置。 
（3）计算测试集数据的预测结果，将输出结果放入答题卡对应位置（输出结果保存为 txt
格式并命名为task5result.txt，不能截图）。 
输出txt格式的数据每一行是测试集对应房源的预测价格（一定要符合格式要求，否
则自动评分程序无法正确执行） 
例： 
800 
120 
615 
… 
（共30行） 
注：最终需要在规定位置提交的文件包括答题卡和task5result.txt。 
24 
【2022网络赛】 
任务：“第五部分”文件夹为本题的数据文件。根据贷款人的相关画像特征预测其是否
会发生债务违约。（数据为train.csv,test.csv） 
注：训练集最后一列为标签，测试集没有标签。 
要求与说明： 
（1）根据训练集数据训练一个债务违约预测模型，不限制模型，根据最终预测准确率排名 
赋分。 
（2）按解决问题的顺序简要介绍每一步的目的，并给出相应代码，放入答题卡对应位置。 
（3）计算训练好的模型在测试集数据的预测结果，将输出结果放入比赛环境中本题对应的 
提交目录文件夹（user/Q5 文件夹，输出结果保存为txt 格式并命名为task5result.txt， 
不能截图）。 
输出txt 格式的数据每一行是测试集对应行的债务违约结果，即0或者1（一定要符合
格式要求，否则自动评分程序无法正确执行） 
例： 
0 
1 
0 
… 
（共3000 行） 
25 
【2022省决赛】 
任务：“第五部分”文件夹为本题的数据文件。预测评论情感的正负性（每一行是一条样
本,正向情感用1表示，负向情感用0表示）。（数据为train.txt,test.txt） 
注：训练集每一行第一个数字为情感标签，测试集没有标签。 
要求与说明： 
（1）根据训练集数据训练一个评论情感预测模型，不限制模型，根据最终预测准确率排名 
赋分。 
（2）按解决问题的顺序简要介绍每一步的目的，并给出相应代码，放入答题卡对应位置。 
（3）计算训练好的模型在测试集数据的预测结果，将输出结果放入比赛环境中本题对应的 
提交目录文件夹（user/Q5文件夹，输出结果保存为txt格式并命名为task5result.txt， 
不能截图）。 
输出txt格式的数据每一行是测试集对应行的情感预测结果，即0或者1（一定要符合 
格式要求，否则自动评分程序无法正确执行） 
例： 
0 
1 
0 
… 
（共2000行） 
26 
【2023网络赛】 
任务：“data/task5”文件夹为本题的数据文件。使用 Python 编程实现一个基于 TF-IDF
的简单中文摘要系统对task5data.txt中的文本进行摘要。 
要求与说明： 
（1）本题文件夹内提供了 jieba 0.42.1 中文分词工具，可通过解压后使用命令 python 
setup.py install 安装，其它安装方式亦可； 
jieba 分词使用方式示例如下： 
import jieba 
seg_list = jieba.cut("我来到北京清华大学") 
print("/ ".join(seg_list))  
jieba 获得语句关键词tf-idf权重使用方式示例如下： 
from jieba.analyse import tfidf 
sentence = '合肥市科技局发布关于发展合肥市人工智能项目的通知' 
print(tfidf(sentence, withWeight=True)) 
（2）基于TF-IDF的简单中文摘要系统构建流程如下图所示，其中，jieba返回的tf-idf的
结果已包含分词和去停用词，句子重要度可简化为该句子所有关键词tf-idf值之和，筛选
关键句通过重要度排序形式进行直接筛选。（如果有重复语句，摘要结果只保留一个）。 
（3）最终的摘要结果为重要度最大的三句。 
（4）将所有源代码与输出结果放入题卡对应位置。 
27 
【2023省决赛】 
任务：“data/task5”文件夹为本题的数据文件。使用Python编程实现一个中文新闻标题
分类算法。 
要求与说明： 
（2）本题文件夹内提供了停用词表hit_stopwords.txt 和 jieba 0.42.1 中文分词工具，
可通过解压后使用命令python setup.py install安装，其它安装方式亦可； 
jieba 分词使用方式示例如下： 
import jieba 
seg_list = jieba.cut("我来到北京清华大学") 
print("/ ".join(seg_list))  
（2）train_4_4000.txt 为训练集，第一列为新闻标题，第二列为类别标签。test_4_400.txt
为测试集，classes.txt为类别和数据相关说明。 
（3）在训练集进行训练，不限制模型。分别输出训练集和测试集的分类准确率（注意选择
模型的类型和大小，由于竞赛平台算力限制，过于复杂的模型可能会导致竞赛平台卡死，需
重新初始化进入）。 
（4）将所有源代码截图与输出结果截图放入答题区域。 